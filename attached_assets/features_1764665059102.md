# Renvo AI - Intelligent Data Cleaning Assistant

## Complete Feature Documentation

---

## Table of Contents
1. [Overview](#overview)
2. [Home Page & Data Upload](#1-home-page--data-upload)
3. [Anomaly Detection](#2-anomaly-detection)
4. [Column Analysis](#3-column-analysis)
5. [Cleaning Wizard](#4-cleaning-wizard)
6. [Visualization](#5-visualization)
7. [Hypothesis Analysis](#6-hypothesis-analysis)
8. [Data Balancer](#7-data-balancer)
9. [AI Assistant](#8-ai-assistant)
10. [Reports](#9-reports)

---

## Overview

Renvo AI is an AI-powered data cleaning tool designed specifically for statistical agencies and data scientists. The application analyzes each column individually and provides context-specific cleaning recommendations while maintaining statistical rigor for survey data.

### Key Capabilities

- **Individual Column Analysis**: Each column is analyzed separately with tailored recommendations
- **AI-Powered Assistance**: Context-aware guidance using advanced language models (Groq)
- **Multiple Cleaning Strategies**: Various methods for handling missing values, outliers, and inconsistencies
- **Comprehensive Audit Trail**: Track all cleaning operations with undo/redo functionality
- **Statistical Rigor**: Maintain methodological consistency for survey data
- **Survey Weights Support**: Integrated survey design weights for weighted analysis

### Supported File Formats

- CSV files (.csv)
- Excel files (.xlsx, .xls)

---

## 1. Home Page & Data Upload

### 1.1 Data Upload

**Feature**: File uploader supporting CSV and Excel formats

**Functionality**:
- Automatic file type detection
- Dataset loading with row/column count display
- Memory usage calculation
- Immediate feedback on upload success/failure

### 1.2 Dataset Overview

**Metrics Displayed**:
- Total Rows
- Total Columns
- Missing Values (total count)
- Memory Usage (in MB)

### 1.3 Data Preview

**Features**:
- Adjustable row preview (5-100 rows)
- Optional column info display showing:
  - Column name
  - Data type
  - Non-null count
  - Missing count
  - Missing percentage
  - Unique values count

### 1.4 Column Type Configuration

**Auto-Detection**: System automatically detects column types

**Available Column Types**:
| Type | Description |
|------|-------------|
| `continuous` | Continuous numeric data (e.g., age, income, measurements) |
| `integer` | Integer numeric data (e.g., count of items, number of children) |
| `ordinal` | Ordered categories (e.g., education level, satisfaction rating) |
| `categorical` | Unordered categories (e.g., gender, region, occupation) |
| `binary` | Two-category variables (e.g., yes/no, male/female) |
| `text` | Free text data (e.g., comments, descriptions) |
| `datetime` | Date and time information |
| `empty` | Columns with no data |
| `unknown` | Unable to determine type automatically |

**Actions**:
- Update Column Types
- Start Column Analysis

### 1.5 Configuration Management

**Features**:
- Export Configuration (JSON format with timestamp)
- Import Configuration (restore previously saved settings)

### 1.6 Data Quality Warnings

- High missing data rate warning (>20% missing values)
- Large dataset notification (>50,000 rows)

---

## 2. Anomaly Detection

### 2.1 Type Anomalies Detection

**Purpose**: Detect values that don't match their declared data type

**Detection Types**:
- Text in numeric columns
- Invalid date formats
- Unexpected values in binary/categorical columns
- Data type mismatches

**Features**:
- Column-by-column scanning
- Anomaly count and percentage
- Detailed anomaly table showing:
  - Row index
  - Anomalous value
  - Reason for anomaly

**Fix Options**:
1. **Set All Anomalous Cells to Null**: Bulk operation to nullify all anomalies
2. **Replace Values Individually**: One-by-one replacement with custom values
3. **Batch Replace**: Replace all anomalies with a single specified value

**Post-Fix Actions**:
- Automatic column type conversion
- Backup creation before modifications
- Cleaning operation logging

### 2.2 Duplicate Removal

**Detection Modes**:
- Complete duplicate rows (all columns must match)
- Subset-based duplicates (user-selected columns)

**Configuration Options**:
- Select specific columns for duplicate detection
- Choose which duplicate to keep:
  - `first`: Keep first occurrence
  - `last`: Keep last occurrence
  - `none`: Remove all duplicates

**Metrics Displayed**:
- Total rows
- Complete duplicate rows count
- Duplicate percentage

**Features**:
- Preview duplicate rows (up to 100 shown)
- Download duplicates as CSV
- Confirmation before removal

### 2.3 Scan All Columns

**Functionality**: Batch scan all columns for anomalies at once

**Output**:
- Summary table showing anomalies per column
- Expected type per column
- Anomaly count and percentage
- Downloadable anomaly report (CSV)

---

## 3. Column Analysis

### 3.1 Inter-Column Violation Detection

**Automatic Checks**:
- Cross-column rule violations
- Severity assessment (low, moderate, high)
- Violation type classification

**Display**:
- Total violations count
- Severity indicator
- Detailed rule checks with columns involved

### 3.2 Individual Column Analysis

**Analysis Tabs**:

#### 3.2.1 Basic Info Tab

**Metrics**:
- Total values count
- Missing values count
- Missing percentage
- Unique values count

**For Numeric Columns**:
- Mean
- Median
- Standard Deviation
- Range (min-max)

**Data Quality Assessment**:
- Quality Score (0-100)
- Quality Grade (A-F)
- Issues identified

#### 3.2.2 Missing Data Tab

**Analysis Provides**:
- Total missing count
- Missing percentage
- Pattern type detection:
  - Sporadic (<5% missing, random scatter)
  - Random (randomly distributed)
  - Systematic Blocks (consecutive blocks)
  - Front Loaded (most at beginning)
  - Tail Loaded (most at end)
- Maximum consecutive missing values
- Visual pattern plot

#### 3.2.3 Outliers Tab

**Detection Methods**:
| Method | Description |
|--------|-------------|
| IQR | Interquartile Range method |
| Z-Score | Standard deviation based |
| Modified Z-Score | Robust to outliers |
| Isolation Forest | Machine learning based |

**Output Per Method**:
- Outliers found count
- Percentage of outliers
- Lower/upper bounds
- Sample outlier values
- Outlier visualization

**Severity Assessment**: High, Moderate, Low

#### 3.2.4 Distribution Tab

**Numeric Distributions**:
- Distribution plot (histogram/density)
- Skewness calculation with interpretation:
  - Near 0: Approximately Normal
  - |skew| < 1: Moderately Skewed
  - |skew| â‰¥ 1: Highly Skewed
- Kurtosis calculation:
  - Platykurtic (flat)
  - Mesokurtic (normal-like)
  - Leptokurtic (peaked)
- Normality Test (Shapiro-Wilk) with p-value

**Quartile Analysis**:
- Minimum, Q1 (25%), Median (50%), Q3 (75%), Maximum

**Categorical Distributions**:
- Frequency distribution table
- Category counts with percentages
- Unique categories count
- Most/Least common categories
- Entropy score (distribution uniformity)

#### 3.2.5 Rule Violations Tab

**Detection of**:
- Logical inconsistencies between columns
- Business rule violations
- Data integrity issues

#### 3.2.6 Recommendations Tab

**AI-Generated Recommendations** for:
- Cleaning methods
- Imputation strategies
- Outlier handling
- Data quality improvements

### 3.3 Quick Overview

**All Columns Overview**:
- Column overview visualization
- Missing patterns heatmap

### 3.4 Batch Analysis

**Feature**: Analyze all columns at once with progress indicator

---

## 4. Cleaning Wizard

### 4.1 Undo/Redo System

**Features**:
- Undo last cleaning operation
- Redo last undone operation
- Operation count display

### 4.2 Survey Weights Configuration

**Weight Column Setup**:
- Select weights column from numeric columns
- Weight validation (errors and warnings)
- Configure weights for weighted analysis

**Weight Diagnostics**:
- Mean weight
- Weight range
- Design effect calculation
- Effective N (sample size)

### 4.3 Cleaning Methods

#### 4.3.1 Missing Values Methods

| Method | Description | Applicable To |
|--------|-------------|---------------|
| Mean Imputation | Replace with column mean | Numeric only |
| Median Imputation | Replace with column median | Numeric only |
| Mode Imputation | Replace with most frequent value | Categorical |
| Forward Fill | Carry forward last valid value | All |
| Backward Fill | Carry backward next valid value | All |
| KNN Imputation | Use k-nearest neighbors | Numeric only |
| Interpolation | Linear/polynomial/spline | Numeric only |
| Missing Category | Create "Missing" category | Categorical |
| Regression Imputation | Predict using regression | Numeric only |

#### 4.3.2 Outlier Methods

| Method | Description |
|--------|-------------|
| IQR Removal | Remove values outside IQR bounds |
| Z-Score Removal | Remove values beyond z-score threshold |
| Winsorization | Cap extreme values at percentiles |
| Log Transformation | Apply log transform to reduce skew |
| Cap Outliers | Replace outliers with boundary values |
| Isolation Forest | ML-based outlier removal |

#### 4.3.3 Data Quality Methods

| Method | Description |
|--------|-------------|
| Type Standardization | Convert to target type (numeric/string/datetime) |
| Remove Duplicates | Remove duplicate rows |
| Trim Whitespace | Remove leading/trailing spaces |
| Standardize Case | Convert to lower/upper/title case |

### 4.4 Method Parameters

**Configurable Parameters by Method**:
- KNN: Number of neighbors (3-10)
- Interpolation: Method (linear, polynomial, spline)
- Missing Category: Custom category name
- Winsorization: Lower/upper percentiles
- IQR Removal: Multiplier (1.0-3.0)
- Z-Score Removal: Threshold (2.0-4.0)
- Cap Outliers: Method (IQR or percentile)
- Type Standardization: Target type
- Case Standardization: Case type
- Isolation Forest: Contamination rate

### 4.5 Preview and Apply

**Preview Features**:
- Impact statistics:
  - Rows affected
  - Percentage changed
  - Missing before/after
- Statistical comparison (before vs after)
- Visual comparison chart
- Sample data changes table

**Apply Process**:
- Automatic backup creation
- Operation logging
- Confirmation required

### 4.6 AI Guidance

**Quick Questions**:
- Is this the best method for this column?
- What are the risks?
- How will this affect my analysis?
- Are there better alternatives?

**Context-Aware AI Analysis**:
- Method-specific recommendations
- Impact assessment
- Alternative suggestions

### 4.7 Cleaning History

**Per Column**:
- Operations applied count
- Method names
- Timestamps
- Parameters used
- Impact statistics

**Overall Progress**:
- Total operations count
- Columns cleaned count

### 4.8 Sidebar Features

**Cleaning Status**:
- Progress bar (columns cleaned/total)
- Column quality overview sorted by score
- Quality color coding (green/orange/red)

**Quick Actions**:
- Export cleaned data (CSV/Excel)
- Validate data button

---

## 5. Visualization

### 5.1 Custom Visualization Builder

**Available Chart Types**:
| Chart Type | Icon | Best For |
|------------|------|----------|
| Bar Chart | ðŸ“Š | Category comparisons |
| Line Chart | ðŸ“ˆ | Trends over index/time |
| Scatter Plot | ðŸ”µ | Relationship between 2 variables |
| Box Plot | ðŸ“¦ | Distribution comparison |
| Violin Plot | ðŸŽ» | Distribution with density |
| Histogram | ðŸ“Š | Frequency distribution |
| KDE Plot | ðŸ“ˆ | Kernel density estimate |
| Q-Q Plot | ðŸ“‰ | Normality assessment |
| Pie Chart | ðŸ¥§ | Proportions |
| Heatmap | ðŸ”¥ | Correlation matrix |
| Correlation Matrix | ðŸ”— | Multi-variable correlations |

**Configuration Options**:
- Custom chart title
- Adjustable height (300-800px)
- Show/hide legend

### 5.2 Chart-Specific Features

**Bar Chart**:
- Single column: Value distribution
- Two columns: Grouped bars

**Scatter Plot**:
- Support for color variable (3rd column)
- Support for size variable (4th column)

**Q-Q Plot**:
- Theoretical quantiles vs sample quantiles
- Best fit line
- Perfect normal reference line

**KDE Plot**:
- Multi-column overlay support
- Filled area visualization

### 5.3 Save and Export

**Features**:
- Save to report collection
- Download as PNG
- Data quality indicator showing cleaned data status

### 5.4 Saved Visualizations

**Management**:
- View all saved visualizations
- Remove individual visualizations
- Clear all visualizations
- Download individual charts

### 5.5 Data Quality Dashboard

**Quick Metrics**:
- Missing data percentage
- Analyzed columns count
- Cleaned columns count
- Average quality score

---

## 6. Hypothesis Analysis

### 6.1 AI-Powered Test Suggestion

**Input**: Natural language research question

**Examples**:
- "Compare means between two or more groups"
- "Find correlation between two variables"
- "Test if my data is normally distributed"
- "Test if categorical data follows expected distribution"

**AI Output**:
- Primary recommendation with:
  - Test name
  - Category (parametric/non-parametric)
  - Rationale
  - Confidence level
- Alternative recommendations
- Warnings
- Suggested columns

### 6.2 Manual Test Selection

**Categories**:
- **Parametric Tests**: Assume normal distribution
- **Non-Parametric Tests**: Distribution-free

**Subcategories**:
- Comparison tests
- Correlation tests
- Goodness of fit tests

### 6.3 Available Statistical Tests (24+)

#### Parametric Tests

| Test | Purpose |
|------|---------|
| One-sample t-test | Compare mean to known value |
| Independent t-test | Compare means of 2 independent groups |
| Welch's t-test | Compare means (unequal variances) |
| Paired t-test | Compare means of paired samples |
| One-way ANOVA | Compare means of 3+ groups |
| Two-way ANOVA | Factorial design comparison |
| Pearson Correlation | Linear relationship strength |
| Simple Linear Regression | Predict Y from X |

#### Non-Parametric Tests

| Test | Purpose |
|------|---------|
| Mann-Whitney U | Compare 2 groups (ordinal/non-normal) |
| Wilcoxon Signed-Rank | Paired comparison (non-parametric) |
| Sign Test | Paired comparison (simple) |
| Kruskal-Wallis | Compare 3+ groups (non-parametric) |
| Friedman Test | Repeated measures (non-parametric) |
| Spearman Correlation | Monotonic relationship |
| Kendall's Tau | Ranked correlation |
| Chi-Square Independence | Association between categories |
| Chi-Square Goodness of Fit | Distribution comparison |
| Fisher's Exact Test | 2x2 contingency table |
| McNemar's Test | Paired categorical data |
| Shapiro-Wilk | Normality test |
| Anderson-Darling | Normality test |
| Kolmogorov-Smirnov | Distribution comparison |
| Levene's Test | Equal variance test |
| Bartlett's Test | Homogeneity of variances |
| One-Sample Proportion Test | Proportion vs hypothesized value |
| Two-Sample Proportion Test | Compare two proportions |

### 6.4 Test Configuration

**Common Settings**:
- Significance level (Î±): 0.01 - 0.10 (default 0.05)
- Sample data option
- Auto-calculate sample size

**Column Filtering**:
- Automatic filtering for applicable columns
- Minimum data requirements enforcement

### 6.5 Test Results

**Output Includes**:
- Test statistic
- p-value
- Decision (reject/fail to reject H0)
- Effect size (Cohen's d, CramÃ©r's V, etc.)
- Confidence interval
- Degrees of freedom
- Sample sizes
- Group statistics
- Assumption checks
- Interpretation
- Warnings

### 6.6 Results Management

**Features**:
- View all test results
- Remove individual results
- Clear all results
- Generate report with results

---

## 7. Data Balancer

### 7.1 Purpose

Balance datasets for machine learning by handling class imbalance in target variables.

### 7.2 Column Selection

**Requirements**:
- Feature columns: Must be numeric
- Target column: Class to balance (numeric or categorical)

### 7.3 Data Validation

**Checks**:
- No missing values in selected columns
- Numeric feature columns
- At least 2 classes in target
- Warning if >10 classes
- Minimum 10 rows required

### 7.4 Class Distribution Analysis

**Displays**:
- Class counts table
- Percentage per class
- Visual bar chart
- Imbalance ratio calculation

### 7.5 Data Usage Options

**Options**:
1. **Use Whole Data**: Balance entire dataset
2. **Use Split Data**: Stratified train/test split first

**Stratified Split Configuration**:
- Test percentage (10-40%)
- Training/test set distribution display
- Preserves class proportions in both sets

### 7.6 Balancing Methods

#### Oversampling (Increase Minority)

| Method | Description |
|--------|-------------|
| Random Oversampling | Randomly duplicate minority samples |
| SMOTE | Create synthetic samples using k-nearest neighbors |

#### Undersampling (Reduce Majority)

| Method | Description |
|--------|-------------|
| Random Undersampling | Randomly remove majority samples |
| Tomek Links | Remove borderline majority samples |
| NearMiss-1 | Keep majority samples closest to minority |
| NearMiss-2 | Keep majority samples farthest from minority |
| NearMiss-3 | Keep M closest majority for each minority |
| ENN (Edited Nearest Neighbours) | Remove samples differing from neighbors |
| CNN (Condensed Nearest Neighbour) | Find consistent subset |
| OSS (One-Sided Selection) | Combines Tomek Links and CNN |
| Cluster Centroids | Replace with cluster centroids |
| NCR (Neighbourhood Cleaning Rule) | Remove noisy samples |

#### Hybrid Methods

| Method | Description |
|--------|-------------|
| SMOTE + Tomek Links | Apply SMOTE then remove Tomek links |
| SMOTE + ENN | Apply SMOTE then clean with ENN |

### 7.7 Results Display

**Metrics**:
- Original size
- Balanced size
- Size change percentage

**Visualizations**:
- Before/After class distribution tables
- Before/After bar charts

### 7.8 Data Download

**Export Options**:
- Balanced training data (CSV/Excel)
- Original test data (if split used)
- Preview before download

---

## 8. AI Assistant

### 8.1 Context Modes

| Mode | Purpose |
|------|---------|
| General Data Cleaning | Overall dataset guidance |
| Specific Column | Column-focused advice |
| Workflow Guidance | Step-by-step process help |

### 8.2 Quick Actions

| Action | Function |
|--------|----------|
| Dataset Overview | Highlight main data quality issues |
| Smart Recommendations | Intelligent cleaning recommendations |
| Explain Concept | Statistical concept explanations |
| Impact Assessment | Assess cleaning method impact |

### 8.3 Explainable Concepts

- Missing data patterns
- Outlier detection
- Imputation methods
- Data normalization
- Survey weights
- Sampling bias

### 8.4 Chat Interface

**Features**:
- Free-form question input
- Conversation history display
- Message timestamps
- Context indicators

**Message Actions**:
- Mark as helpful
- Request follow-up
- Ask for rephrase
- Copy response

### 8.5 Suggested Questions

**Categories**:

**General Questions**:
- Best approach to clean dataset
- Prioritizing column cleaning
- Risks of removing outliers
- Validating cleaning results

**Column-Specific Questions**:
- Best imputation method
- Handling outliers
- Missing data pattern meaning
- Cleaning method bias

**Statistical Questions**:
- Preserving survey weights
- MCAR, MAR, MNAR differences
- When to use multiple imputation
- Impact assessment methods

### 8.6 Export Features

- Download conversation (text file)
- Generate summary
- Copy all as JSON

### 8.7 Sidebar Context

**AI Status**:
- Connection status
- Model information

**Session Statistics**:
- Total messages
- Your questions count
- AI responses count

**Current Context Display**:
- Active mode
- Selected column info
- Quality score

**Dataset Context**:
- Rows/columns count
- Missing values total
- Analyzed/cleaned counts

---

## 9. Reports

### 9.1 Data Export Options

**Formats**:
- Cleaned dataset (CSV)
- Original dataset (CSV)

### 9.2 Dataset Preview Tabs

#### Current Data Tab
- Preview first 100 rows of cleaned data

#### Summary Statistics Tab
- Total rows/columns
- Missing values count
- Columns cleaned count
- Numeric columns summary (describe())

#### Data Comparison Tab
- Column-by-column comparison with original
- Missing value changes
- Cleaned status indicator

### 9.3 Report Configuration

**Report Types**:
| Type | Content |
|------|---------|
| Executive Summary | High-level overview |
| Detailed Analysis | In-depth column analysis |
| Methodology Documentation | Methods and parameters used |
| Complete Audit Trail | Full operation history |

**Export Formats**:
- PDF Document
- Markdown
- HTML
- JSON

### 9.4 Report Generation

**PDF Report Includes**:
- Column analyses
- Anomaly detections
- Saved visualizations
- Cleaning operations

### 9.5 Supporting Visualizations

**Auto-Generated Charts**:

#### Dataset Overview
- Column overview visualization
- Basic statistics table

#### Missing Patterns
- Missing data heatmap
- Columns with missing data table

#### Data Quality
- Quality scores per column
- Grade distribution
- Average quality score

#### Correlations
- Correlation matrix heatmap
- High correlation pairs (|r| > 0.7)

### 9.6 Custom Visualizations

- Include saved charts from Visualization page
- Interactive preview in report

### 9.7 Cleaning Operations Summary

**Per Column**:
- Operations applied count
- Last method used
- Last applied timestamp

**Timeline View**:
- Chronological operation list
- 20 most recent operations

### 9.8 Report Statistics

**Metrics**:
- Analysis progress (%)
- Cleaning progress (%)
- Missing data reduced (%)
- Average quality score

### 9.9 Recommendations & Next Steps

**Auto-Generated Recommendations**:
- Unanalyzed columns to analyze
- Columns to consider cleaning
- Low-quality columns to address
- Validation recommendations

---

## Technical Specifications

### Session State Management

- Dataset storage and versioning
- Original dataset preservation
- Column type configurations
- Analysis results caching
- Cleaning history tracking
- Undo/redo stacks

### Dependencies

**Core Libraries**:
- Streamlit (UI framework)
- Pandas (data manipulation)
- NumPy (numerical operations)
- SciPy (statistical tests)
- Scikit-learn (ML algorithms)
- Statsmodels (statistical models)
- Plotly (visualizations)
- Seaborn/Matplotlib (additional plots)
- imbalanced-learn (data balancing)
- Groq (AI assistant)
- ReportLab (PDF generation)
- OpenPyXL (Excel support)

### AI Integration

- Provider: Groq
- Model: Configurable via API
- Use cases: Test suggestions, cleaning recommendations, concept explanations

---

## Best Practices

### Recommended Workflow

1. **Upload Data** â†’ Review column types
2. **Detect Anomalies** â†’ Fix data type issues
3. **Remove Duplicates** â†’ Clean duplicate rows
4. **Analyze Columns** â†’ Understand data quality
5. **Apply Cleaning** â†’ Handle missing/outliers
6. **Visualize** â†’ Verify distributions
7. **Run Tests** â†’ Validate hypotheses
8. **Balance Data** â†’ Prepare for ML (if needed)
9. **Generate Report** â†’ Document everything

### Tips

- Always backup before major operations
- Use preview before applying changes
- Check assumption violations
- Document cleaning decisions
- Export configurations for reproducibility

---

*Last Updated: 2025*
